{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Homework 3: Neural Network**\n",
    "1. Pakapak Silpapinun ID:62340500042\n",
    "2. Supana Somtuy ID:62340500055"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('https://raw.githubusercontent.com/SniiceS/503-HW3/main/Data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('https://raw.githubusercontent.com/SniiceS/503-HW3/main/Data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 785)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create the machine learning neural netwotk model, we use tensorflow. First, we separate output from the dataset. Then we change the numeric label value to nominal value to perform a classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "\n",
    "x = df_train.iloc[:,1:]    # attribute\n",
    "row,col = x.shape\n",
    "onehot_label = np.zeros((row,10))   # to classify the multi-class classification\n",
    "for i in range(row):\n",
    "    onehot_label[i, df_train.label[i]] = 1\n",
    "y = pd.DataFrame(onehot_label,columns=['0','1','2','3','4','5','6','7','8','9'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the model with 2 hidden layer containing 28 and 10 nodes, respectively. For the activation fuction in hidden nodes, we use sigmoid function (on-off choice). For the output layer, the softmax function is applied (it was suggested for the classification problem)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(28,activation='sigmoid'))\n",
    "model.add(Dense(14,activation='sigmoid'))\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='sgd',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then to perform a stop criteria, we decide to stop the training when the loss is constant for 50 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "42000/42000 [==============================] - 16s 379us/step - loss: 0.2757 - accuracy: 0.4963\n",
      "Epoch 2/200\n",
      "42000/42000 [==============================] - 16s 371us/step - loss: 0.1954 - accuracy: 0.6608\n",
      "Epoch 3/200\n",
      "42000/42000 [==============================] - 16s 376us/step - loss: 0.1634 - accuracy: 0.7303\n",
      "Epoch 4/200\n",
      "42000/42000 [==============================] - 17s 397us/step - loss: 0.1500 - accuracy: 0.7412\n",
      "Epoch 5/200\n",
      "42000/42000 [==============================] - 15s 365us/step - loss: 0.1350 - accuracy: 0.7745\n",
      "Epoch 6/200\n",
      "42000/42000 [==============================] - 15s 360us/step - loss: 0.1354 - accuracy: 0.7766\n",
      "Epoch 7/200\n",
      "42000/42000 [==============================] - 15s 357us/step - loss: 0.1245 - accuracy: 0.7934\n",
      "Epoch 8/200\n",
      "42000/42000 [==============================] - 15s 355us/step - loss: 0.1196 - accuracy: 0.8060\n",
      "Epoch 9/200\n",
      "42000/42000 [==============================] - 15s 367us/step - loss: 0.1246 - accuracy: 0.7835\n",
      "Epoch 10/200\n",
      "42000/42000 [==============================] - 15s 363us/step - loss: 0.1138 - accuracy: 0.8103\n",
      "Epoch 11/200\n",
      "42000/42000 [==============================] - 16s 372us/step - loss: 0.1079 - accuracy: 0.8221\n",
      "Epoch 12/200\n",
      "42000/42000 [==============================] - 16s 379us/step - loss: 0.1104 - accuracy: 0.8140\n",
      "Epoch 13/200\n",
      "42000/42000 [==============================] - 16s 384us/step - loss: 0.1126 - accuracy: 0.8051\n",
      "Epoch 14/200\n",
      "42000/42000 [==============================] - 15s 360us/step - loss: 0.1038 - accuracy: 0.8246\n",
      "Epoch 15/200\n",
      "42000/42000 [==============================] - 15s 355us/step - loss: 0.1059 - accuracy: 0.8160\n",
      "Epoch 16/200\n",
      "42000/42000 [==============================] - 16s 381us/step - loss: 0.1054 - accuracy: 0.8178\n",
      "Epoch 17/200\n",
      "42000/42000 [==============================] - 16s 378us/step - loss: 0.1180 - accuracy: 0.7841\n",
      "Epoch 18/200\n",
      "42000/42000 [==============================] - 16s 371us/step - loss: 0.1110 - accuracy: 0.8014\n",
      "Epoch 19/200\n",
      "42000/42000 [==============================] - 16s 378us/step - loss: 0.1088 - accuracy: 0.8037\n",
      "Epoch 20/200\n",
      "42000/42000 [==============================] - 16s 387us/step - loss: 0.1053 - accuracy: 0.8165\n",
      "Epoch 21/200\n",
      "42000/42000 [==============================] - 16s 373us/step - loss: 0.1122 - accuracy: 0.8001\n",
      "Epoch 22/200\n",
      "42000/42000 [==============================] - 15s 363us/step - loss: 0.1136 - accuracy: 0.7946\n",
      "Epoch 23/200\n",
      "42000/42000 [==============================] - 15s 366us/step - loss: 0.1127 - accuracy: 0.8037\n",
      "Epoch 24/200\n",
      "42000/42000 [==============================] - 15s 366us/step - loss: 0.1139 - accuracy: 0.7875\n",
      "Epoch 25/200\n",
      "42000/42000 [==============================] - 15s 363us/step - loss: 0.1071 - accuracy: 0.8091\n",
      "Epoch 26/200\n",
      "42000/42000 [==============================] - 16s 374us/step - loss: 0.0989 - accuracy: 0.8248\n",
      "Epoch 27/200\n",
      "42000/42000 [==============================] - 16s 370us/step - loss: 0.0977 - accuracy: 0.8271\n",
      "Epoch 28/200\n",
      "42000/42000 [==============================] - 15s 366us/step - loss: 0.0947 - accuracy: 0.8339\n",
      "Epoch 29/200\n",
      "42000/42000 [==============================] - 15s 367us/step - loss: 0.0895 - accuracy: 0.8469\n",
      "Epoch 30/200\n",
      "42000/42000 [==============================] - 15s 358us/step - loss: 0.0879 - accuracy: 0.8528\n",
      "Epoch 31/200\n",
      "42000/42000 [==============================] - 15s 367us/step - loss: 0.0888 - accuracy: 0.8473\n",
      "Epoch 32/200\n",
      "42000/42000 [==============================] - 16s 377us/step - loss: 0.0923 - accuracy: 0.8359\n",
      "Epoch 33/200\n",
      "42000/42000 [==============================] - 15s 346us/step - loss: 0.0909 - accuracy: 0.8400\n",
      "Epoch 34/200\n",
      "42000/42000 [==============================] - 15s 346us/step - loss: 0.0868 - accuracy: 0.8530\n",
      "Epoch 35/200\n",
      "42000/42000 [==============================] - 15s 348us/step - loss: 0.0864 - accuracy: 0.8501\n",
      "Epoch 36/200\n",
      "42000/42000 [==============================] - 14s 344us/step - loss: 0.0840 - accuracy: 0.8550\n",
      "Epoch 37/200\n",
      "42000/42000 [==============================] - 14s 342us/step - loss: 0.0882 - accuracy: 0.8466\n",
      "Epoch 38/200\n",
      "42000/42000 [==============================] - 15s 352us/step - loss: 0.0882 - accuracy: 0.8495\n",
      "Epoch 39/200\n",
      "42000/42000 [==============================] - 14s 337us/step - loss: 0.0853 - accuracy: 0.8563\n",
      "Epoch 40/200\n",
      "42000/42000 [==============================] - 15s 346us/step - loss: 0.0830 - accuracy: 0.8596\n",
      "Epoch 41/200\n",
      "42000/42000 [==============================] - 15s 349us/step - loss: 0.0866 - accuracy: 0.8555\n",
      "Epoch 42/200\n",
      "42000/42000 [==============================] - 15s 346us/step - loss: 0.0852 - accuracy: 0.8567\n",
      "Epoch 43/200\n",
      "42000/42000 [==============================] - 15s 349us/step - loss: 0.0834 - accuracy: 0.8577\n",
      "Epoch 44/200\n",
      "42000/42000 [==============================] - 14s 343us/step - loss: 0.0857 - accuracy: 0.8525\n",
      "Epoch 45/200\n",
      "42000/42000 [==============================] - 14s 344us/step - loss: 0.0845 - accuracy: 0.8568\n",
      "Epoch 46/200\n",
      "42000/42000 [==============================] - 15s 362us/step - loss: 0.0954 - accuracy: 0.8323\n",
      "Epoch 47/200\n",
      "42000/42000 [==============================] - 15s 349us/step - loss: 0.0920 - accuracy: 0.8346\n",
      "Epoch 48/200\n",
      "42000/42000 [==============================] - 15s 358us/step - loss: 0.0831 - accuracy: 0.8573\n",
      "Epoch 49/200\n",
      "42000/42000 [==============================] - 15s 349us/step - loss: 0.0793 - accuracy: 0.8663\n",
      "Epoch 50/200\n",
      "42000/42000 [==============================] - 15s 357us/step - loss: 0.0802 - accuracy: 0.8662\n",
      "Epoch 51/200\n",
      "42000/42000 [==============================] - 14s 345us/step - loss: 0.0771 - accuracy: 0.8696\n",
      "Epoch 52/200\n",
      "42000/42000 [==============================] - 14s 341us/step - loss: 0.0851 - accuracy: 0.8539\n",
      "Epoch 53/200\n",
      "42000/42000 [==============================] - 14s 343us/step - loss: 0.0855 - accuracy: 0.8532\n",
      "Epoch 54/200\n",
      "42000/42000 [==============================] - 15s 349us/step - loss: 0.0779 - accuracy: 0.8700\n",
      "Epoch 55/200\n",
      "42000/42000 [==============================] - 14s 340us/step - loss: 0.0815 - accuracy: 0.8617\n",
      "Epoch 56/200\n",
      "42000/42000 [==============================] - 14s 338us/step - loss: 0.0745 - accuracy: 0.8786\n",
      "Epoch 57/200\n",
      "42000/42000 [==============================] - 14s 342us/step - loss: 0.0737 - accuracy: 0.8788\n",
      "Epoch 58/200\n",
      "42000/42000 [==============================] - 15s 347us/step - loss: 0.0776 - accuracy: 0.8702\n",
      "Epoch 59/200\n",
      "42000/42000 [==============================] - 14s 338us/step - loss: 0.0713 - accuracy: 0.8810\n",
      "Epoch 60/200\n",
      "42000/42000 [==============================] - 14s 340us/step - loss: 0.0783 - accuracy: 0.8645\n",
      "Epoch 61/200\n",
      "42000/42000 [==============================] - 14s 341us/step - loss: 0.0802 - accuracy: 0.8622\n",
      "Epoch 62/200\n",
      "42000/42000 [==============================] - 14s 340us/step - loss: 0.0786 - accuracy: 0.8652\n",
      "Epoch 63/200\n",
      "42000/42000 [==============================] - 14s 342us/step - loss: 0.0763 - accuracy: 0.8728\n",
      "Epoch 64/200\n",
      "42000/42000 [==============================] - 14s 342us/step - loss: 0.0795 - accuracy: 0.8615\n",
      "Epoch 65/200\n",
      "42000/42000 [==============================] - 14s 339us/step - loss: 0.0756 - accuracy: 0.8705\n",
      "Epoch 66/200\n",
      "42000/42000 [==============================] - 14s 342us/step - loss: 0.0723 - accuracy: 0.8800\n",
      "Epoch 67/200\n",
      "42000/42000 [==============================] - 14s 343us/step - loss: 0.0715 - accuracy: 0.8779\n",
      "Epoch 68/200\n",
      "42000/42000 [==============================] - 14s 341us/step - loss: 0.0755 - accuracy: 0.8744\n",
      "Epoch 69/200\n",
      "42000/42000 [==============================] - 14s 338us/step - loss: 0.0736 - accuracy: 0.8759\n",
      "Epoch 70/200\n",
      "42000/42000 [==============================] - 14s 337us/step - loss: 0.0737 - accuracy: 0.8741\n",
      "Epoch 71/200\n",
      "42000/42000 [==============================] - 14s 338us/step - loss: 0.0760 - accuracy: 0.8706\n",
      "Epoch 72/200\n",
      "42000/42000 [==============================] - 14s 339us/step - loss: 0.0826 - accuracy: 0.8544\n",
      "Epoch 73/200\n",
      "42000/42000 [==============================] - 14s 341us/step - loss: 0.0836 - accuracy: 0.8537\n",
      "Epoch 74/200\n",
      "42000/42000 [==============================] - 14s 343us/step - loss: 0.0798 - accuracy: 0.8622\n",
      "Epoch 75/200\n",
      "42000/42000 [==============================] - 14s 342us/step - loss: 0.0753 - accuracy: 0.8705\n",
      "Epoch 76/200\n",
      "42000/42000 [==============================] - 14s 342us/step - loss: 0.0795 - accuracy: 0.8660\n",
      "Epoch 77/200\n",
      "42000/42000 [==============================] - 15s 348us/step - loss: 0.0803 - accuracy: 0.8608\n",
      "Epoch 78/200\n",
      "42000/42000 [==============================] - 14s 344us/step - loss: 0.0735 - accuracy: 0.8755\n",
      "Epoch 79/200\n",
      "42000/42000 [==============================] - 15s 347us/step - loss: 0.0781 - accuracy: 0.8639\n",
      "Epoch 80/200\n",
      "42000/42000 [==============================] - 14s 339us/step - loss: 0.0815 - accuracy: 0.8596\n",
      "Epoch 81/200\n",
      "42000/42000 [==============================] - 14s 335us/step - loss: 0.0813 - accuracy: 0.8616\n",
      "Epoch 82/200\n",
      "42000/42000 [==============================] - 14s 335us/step - loss: 0.0769 - accuracy: 0.8681\n",
      "Epoch 83/200\n",
      "42000/42000 [==============================] - 14s 335us/step - loss: 0.0758 - accuracy: 0.8654\n",
      "Epoch 84/200\n",
      "42000/42000 [==============================] - 14s 335us/step - loss: 0.0768 - accuracy: 0.8652\n",
      "Epoch 85/200\n",
      "42000/42000 [==============================] - 14s 336us/step - loss: 0.0775 - accuracy: 0.8625\n",
      "Epoch 86/200\n",
      "42000/42000 [==============================] - 14s 336us/step - loss: 0.0777 - accuracy: 0.8680\n",
      "Epoch 87/200\n",
      "42000/42000 [==============================] - 14s 343us/step - loss: 0.0759 - accuracy: 0.8691\n",
      "Epoch 88/200\n",
      "42000/42000 [==============================] - 14s 335us/step - loss: 0.0740 - accuracy: 0.8710\n",
      "Epoch 89/200\n",
      "42000/42000 [==============================] - 14s 336us/step - loss: 0.0748 - accuracy: 0.8706\n",
      "Epoch 90/200\n",
      "42000/42000 [==============================] - 14s 333us/step - loss: 0.0709 - accuracy: 0.8782\n",
      "Epoch 91/200\n",
      "42000/42000 [==============================] - 14s 334us/step - loss: 0.0695 - accuracy: 0.8822\n",
      "Epoch 92/200\n",
      "42000/42000 [==============================] - 14s 335us/step - loss: 0.0714 - accuracy: 0.8800\n",
      "Epoch 93/200\n",
      "42000/42000 [==============================] - 14s 333us/step - loss: 0.0736 - accuracy: 0.8746\n",
      "Epoch 94/200\n",
      "42000/42000 [==============================] - 14s 334us/step - loss: 0.0783 - accuracy: 0.8618\n",
      "Epoch 95/200\n",
      "42000/42000 [==============================] - 14s 333us/step - loss: 0.0779 - accuracy: 0.8646\n",
      "Epoch 96/200\n",
      "42000/42000 [==============================] - 14s 334us/step - loss: 0.0781 - accuracy: 0.8684\n",
      "Epoch 97/200\n",
      "42000/42000 [==============================] - 14s 334us/step - loss: 0.0746 - accuracy: 0.8751\n",
      "Epoch 98/200\n",
      "42000/42000 [==============================] - 14s 335us/step - loss: 0.0726 - accuracy: 0.8779\n",
      "Epoch 99/200\n",
      "42000/42000 [==============================] - 14s 333us/step - loss: 0.0743 - accuracy: 0.8705\n",
      "Epoch 100/200\n",
      "42000/42000 [==============================] - 14s 334us/step - loss: 0.0735 - accuracy: 0.8719\n",
      "Epoch 101/200\n",
      "42000/42000 [==============================] - 14s 335us/step - loss: 0.0698 - accuracy: 0.8805\n",
      "Epoch 102/200\n",
      "42000/42000 [==============================] - 14s 335us/step - loss: 0.0706 - accuracy: 0.8781\n",
      "Epoch 103/200\n",
      "42000/42000 [==============================] - 15s 350us/step - loss: 0.0737 - accuracy: 0.8765\n",
      "Epoch 104/200\n",
      "42000/42000 [==============================] - 15s 351us/step - loss: 0.0744 - accuracy: 0.8748\n",
      "Epoch 105/200\n",
      "42000/42000 [==============================] - 14s 345us/step - loss: 0.0742 - accuracy: 0.8690\n",
      "Epoch 106/200\n",
      "42000/42000 [==============================] - 14s 344us/step - loss: 0.0738 - accuracy: 0.8683\n",
      "Epoch 107/200\n",
      "42000/42000 [==============================] - 15s 361us/step - loss: 0.0733 - accuracy: 0.8672\n",
      "Epoch 108/200\n",
      "42000/42000 [==============================] - 15s 350us/step - loss: 0.0751 - accuracy: 0.8632\n",
      "Epoch 109/200\n",
      "42000/42000 [==============================] - 14s 341us/step - loss: 0.0739 - accuracy: 0.8686\n",
      "Epoch 110/200\n",
      "42000/42000 [==============================] - 14s 341us/step - loss: 0.0721 - accuracy: 0.8737\n",
      "Epoch 111/200\n",
      "42000/42000 [==============================] - 14s 342us/step - loss: 0.0751 - accuracy: 0.8689\n",
      "Epoch 112/200\n",
      "42000/42000 [==============================] - 14s 343us/step - loss: 0.0777 - accuracy: 0.8631\n",
      "Epoch 113/200\n",
      "42000/42000 [==============================] - 14s 343us/step - loss: 0.0722 - accuracy: 0.8749\n",
      "Epoch 114/200\n",
      "42000/42000 [==============================] - 14s 345us/step - loss: 0.0740 - accuracy: 0.8720\n",
      "Epoch 115/200\n",
      "42000/42000 [==============================] - 14s 343us/step - loss: 0.0699 - accuracy: 0.8799\n",
      "Epoch 116/200\n",
      "42000/42000 [==============================] - 14s 339us/step - loss: 0.0665 - accuracy: 0.8859\n",
      "Epoch 117/200\n",
      "42000/42000 [==============================] - 14s 342us/step - loss: 0.0649 - accuracy: 0.8904\n",
      "Epoch 118/200\n",
      "42000/42000 [==============================] - 14s 341us/step - loss: 0.0632 - accuracy: 0.8940\n",
      "Epoch 119/200\n",
      "42000/42000 [==============================] - 14s 339us/step - loss: 0.0620 - accuracy: 0.8958\n",
      "Epoch 120/200\n",
      "42000/42000 [==============================] - 14s 340us/step - loss: 0.0663 - accuracy: 0.8876\n",
      "Epoch 121/200\n",
      "42000/42000 [==============================] - 14s 339us/step - loss: 0.0702 - accuracy: 0.8812\n",
      "Epoch 122/200\n",
      "42000/42000 [==============================] - 14s 342us/step - loss: 0.0681 - accuracy: 0.8844\n",
      "Epoch 123/200\n",
      "42000/42000 [==============================] - 14s 339us/step - loss: 0.0653 - accuracy: 0.8896\n",
      "Epoch 124/200\n",
      "42000/42000 [==============================] - 14s 343us/step - loss: 0.0639 - accuracy: 0.8918\n",
      "Epoch 125/200\n",
      "42000/42000 [==============================] - 14s 341us/step - loss: 0.0616 - accuracy: 0.8974\n",
      "Epoch 126/200\n",
      "42000/42000 [==============================] - 14s 341us/step - loss: 0.0607 - accuracy: 0.8982\n",
      "Epoch 127/200\n",
      "42000/42000 [==============================] - 14s 340us/step - loss: 0.0631 - accuracy: 0.8934\n",
      "Epoch 128/200\n",
      "42000/42000 [==============================] - 14s 342us/step - loss: 0.0613 - accuracy: 0.8979\n",
      "Epoch 129/200\n",
      "42000/42000 [==============================] - 14s 341us/step - loss: 0.0594 - accuracy: 0.8998\n",
      "Epoch 130/200\n",
      "42000/42000 [==============================] - 14s 342us/step - loss: 0.0621 - accuracy: 0.8944\n",
      "Epoch 131/200\n",
      "42000/42000 [==============================] - 14s 340us/step - loss: 0.0649 - accuracy: 0.8871\n",
      "Epoch 132/200\n",
      "42000/42000 [==============================] - 14s 342us/step - loss: 0.0632 - accuracy: 0.8919\n",
      "Epoch 133/200\n",
      "42000/42000 [==============================] - 14s 343us/step - loss: 0.0655 - accuracy: 0.8869\n",
      "Epoch 134/200\n",
      "42000/42000 [==============================] - 14s 342us/step - loss: 0.0674 - accuracy: 0.8828\n",
      "Epoch 135/200\n",
      "42000/42000 [==============================] - 14s 344us/step - loss: 0.0617 - accuracy: 0.8956\n",
      "Epoch 136/200\n",
      "42000/42000 [==============================] - 14s 343us/step - loss: 0.0621 - accuracy: 0.8956\n",
      "Epoch 137/200\n",
      "42000/42000 [==============================] - 15s 350us/step - loss: 0.0652 - accuracy: 0.8923\n",
      "Epoch 138/200\n",
      "42000/42000 [==============================] - 15s 348us/step - loss: 0.0619 - accuracy: 0.8976\n",
      "Epoch 139/200\n",
      "42000/42000 [==============================] - 14s 337us/step - loss: 0.0644 - accuracy: 0.8893\n",
      "Epoch 140/200\n",
      "42000/42000 [==============================] - 14s 345us/step - loss: 0.0639 - accuracy: 0.8888\n",
      "Epoch 141/200\n",
      "42000/42000 [==============================] - 14s 341us/step - loss: 0.0613 - accuracy: 0.8958\n",
      "Epoch 142/200\n",
      "42000/42000 [==============================] - 15s 362us/step - loss: 0.0617 - accuracy: 0.8963\n",
      "Epoch 143/200\n",
      "42000/42000 [==============================] - 15s 348us/step - loss: 0.0625 - accuracy: 0.8934\n",
      "Epoch 144/200\n",
      "42000/42000 [==============================] - 15s 347us/step - loss: 0.0620 - accuracy: 0.8954\n",
      "Epoch 145/200\n",
      "42000/42000 [==============================] - 15s 353us/step - loss: 0.0621 - accuracy: 0.8946\n",
      "Epoch 146/200\n",
      "42000/42000 [==============================] - 15s 351us/step - loss: 0.0597 - accuracy: 0.9003\n",
      "Epoch 147/200\n",
      "42000/42000 [==============================] - 15s 358us/step - loss: 0.0619 - accuracy: 0.8925\n",
      "Epoch 148/200\n",
      "42000/42000 [==============================] - 15s 355us/step - loss: 0.0640 - accuracy: 0.8908\n",
      "Epoch 149/200\n",
      "42000/42000 [==============================] - 15s 355us/step - loss: 0.0627 - accuracy: 0.8961\n",
      "Epoch 150/200\n",
      "42000/42000 [==============================] - 15s 350us/step - loss: 0.0627 - accuracy: 0.8953\n",
      "Epoch 151/200\n",
      "42000/42000 [==============================] - 14s 342us/step - loss: 0.0624 - accuracy: 0.8973\n",
      "Epoch 152/200\n",
      "42000/42000 [==============================] - 14s 341us/step - loss: 0.0612 - accuracy: 0.8994\n",
      "Epoch 153/200\n",
      "42000/42000 [==============================] - 14s 339us/step - loss: 0.0617 - accuracy: 0.8969\n",
      "Epoch 154/200\n",
      "42000/42000 [==============================] - 14s 340us/step - loss: 0.0609 - accuracy: 0.8979\n",
      "Epoch 155/200\n",
      "42000/42000 [==============================] - 14s 338us/step - loss: 0.0616 - accuracy: 0.8967\n",
      "Epoch 156/200\n",
      "42000/42000 [==============================] - 14s 341us/step - loss: 0.0592 - accuracy: 0.9032\n",
      "Epoch 157/200\n",
      "42000/42000 [==============================] - 14s 339us/step - loss: 0.0606 - accuracy: 0.9002\n",
      "Epoch 158/200\n",
      "42000/42000 [==============================] - 14s 339us/step - loss: 0.0630 - accuracy: 0.8907\n",
      "Epoch 159/200\n",
      "42000/42000 [==============================] - 14s 338us/step - loss: 0.0611 - accuracy: 0.8973\n",
      "Epoch 160/200\n",
      "42000/42000 [==============================] - 14s 339us/step - loss: 0.0599 - accuracy: 0.9003\n",
      "Epoch 161/200\n",
      "42000/42000 [==============================] - 14s 339us/step - loss: 0.0638 - accuracy: 0.8913\n",
      "Epoch 162/200\n",
      "42000/42000 [==============================] - 14s 340us/step - loss: 0.0686 - accuracy: 0.8790\n",
      "Epoch 163/200\n",
      "42000/42000 [==============================] - 14s 339us/step - loss: 0.0643 - accuracy: 0.8896\n",
      "Epoch 164/200\n",
      "42000/42000 [==============================] - 14s 340us/step - loss: 0.0592 - accuracy: 0.8995\n",
      "Epoch 165/200\n",
      "42000/42000 [==============================] - 14s 341us/step - loss: 0.0563 - accuracy: 0.9076\n",
      "Epoch 166/200\n",
      "42000/42000 [==============================] - 14s 342us/step - loss: 0.0571 - accuracy: 0.9062\n",
      "Epoch 167/200\n",
      "42000/42000 [==============================] - 14s 341us/step - loss: 0.0592 - accuracy: 0.9023\n",
      "Epoch 168/200\n",
      "42000/42000 [==============================] - 14s 341us/step - loss: 0.0584 - accuracy: 0.9025\n",
      "Epoch 169/200\n",
      "42000/42000 [==============================] - 14s 342us/step - loss: 0.0619 - accuracy: 0.8971\n",
      "Epoch 170/200\n",
      "42000/42000 [==============================] - 14s 340us/step - loss: 0.0622 - accuracy: 0.8960\n",
      "Epoch 171/200\n",
      "42000/42000 [==============================] - 14s 340us/step - loss: 0.0597 - accuracy: 0.9005\n",
      "Epoch 172/200\n",
      "42000/42000 [==============================] - 14s 339us/step - loss: 0.0600 - accuracy: 0.9007\n",
      "Epoch 173/200\n",
      "42000/42000 [==============================] - 14s 340us/step - loss: 0.0600 - accuracy: 0.9003\n",
      "Epoch 174/200\n",
      "42000/42000 [==============================] - 14s 339us/step - loss: 0.0611 - accuracy: 0.8983\n",
      "Epoch 175/200\n",
      "42000/42000 [==============================] - 14s 339us/step - loss: 0.0649 - accuracy: 0.8874\n",
      "Epoch 176/200\n",
      "42000/42000 [==============================] - 14s 338us/step - loss: 0.0602 - accuracy: 0.8995\n",
      "Epoch 177/200\n",
      "42000/42000 [==============================] - 14s 337us/step - loss: 0.0577 - accuracy: 0.9051\n",
      "Epoch 178/200\n",
      "42000/42000 [==============================] - 14s 338us/step - loss: 0.0591 - accuracy: 0.9032\n",
      "Epoch 179/200\n",
      "42000/42000 [==============================] - 14s 337us/step - loss: 0.0590 - accuracy: 0.9024\n",
      "Epoch 180/200\n",
      "42000/42000 [==============================] - 14s 338us/step - loss: 0.0591 - accuracy: 0.9027\n",
      "Epoch 181/200\n",
      "42000/42000 [==============================] - 14s 337us/step - loss: 0.0624 - accuracy: 0.8969\n",
      "Epoch 182/200\n",
      "42000/42000 [==============================] - 14s 340us/step - loss: 0.0647 - accuracy: 0.8900\n",
      "Epoch 183/200\n",
      "42000/42000 [==============================] - 14s 338us/step - loss: 0.0644 - accuracy: 0.8908\n",
      "Epoch 184/200\n",
      "42000/42000 [==============================] - 14s 339us/step - loss: 0.0622 - accuracy: 0.8978\n",
      "Epoch 185/200\n",
      "42000/42000 [==============================] - 14s 340us/step - loss: 0.0605 - accuracy: 0.9004\n",
      "Epoch 186/200\n",
      "42000/42000 [==============================] - 15s 353us/step - loss: 0.0605 - accuracy: 0.9019\n",
      "Epoch 187/200\n",
      "42000/42000 [==============================] - 15s 350us/step - loss: 0.0644 - accuracy: 0.8948\n",
      "Epoch 188/200\n",
      "42000/42000 [==============================] - 15s 350us/step - loss: 0.0628 - accuracy: 0.8975\n",
      "Epoch 189/200\n",
      "42000/42000 [==============================] - 15s 347us/step - loss: 0.0621 - accuracy: 0.8973\n",
      "Epoch 190/200\n",
      "42000/42000 [==============================] - 14s 343us/step - loss: 0.0624 - accuracy: 0.8970\n",
      "Epoch 191/200\n",
      "42000/42000 [==============================] - 14s 341us/step - loss: 0.0612 - accuracy: 0.9014\n",
      "Epoch 192/200\n",
      "42000/42000 [==============================] - 14s 340us/step - loss: 0.0600 - accuracy: 0.9032\n",
      "Epoch 193/200\n",
      "42000/42000 [==============================] - 14s 341us/step - loss: 0.0598 - accuracy: 0.9019\n",
      "Epoch 194/200\n",
      "42000/42000 [==============================] - 14s 336us/step - loss: 0.0599 - accuracy: 0.9020\n",
      "Epoch 195/200\n",
      "42000/42000 [==============================] - 14s 343us/step - loss: 0.0596 - accuracy: 0.9036\n",
      "Epoch 196/200\n",
      "42000/42000 [==============================] - 14s 344us/step - loss: 0.0607 - accuracy: 0.9021\n",
      "Epoch 197/200\n",
      "42000/42000 [==============================] - 14s 345us/step - loss: 0.0631 - accuracy: 0.8954\n",
      "Epoch 198/200\n",
      "42000/42000 [==============================] - 14s 338us/step - loss: 0.0622 - accuracy: 0.8951\n",
      "Epoch 199/200\n",
      "42000/42000 [==============================] - 14s 342us/step - loss: 0.0670 - accuracy: 0.8811\n",
      "Epoch 200/200\n",
      "42000/42000 [==============================] - 14s 341us/step - loss: 0.0643 - accuracy: 0.8882\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=50)\n",
    "history = model.fit(x,y,epochs=200, batch_size=1, callbacks=[callback],verbose=1)\n",
    "len(history.history['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The changing of loss can be seen as following graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x21138a6d880>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the model performance, we apply the model to the testing set and then submit it to the testing serve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ImageId  Label\n",
       "0        1      2\n",
       "1        2      0\n",
       "2        3      9\n",
       "3        4      9\n",
       "4        5      2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model.predict(df_test.values)\n",
    "result = []\n",
    "for i in output:\n",
    "    for j in range(10):\n",
    "        if i[j] == max(i):\n",
    "            result.append([len(result)+1,j])\n",
    "output = pd.DataFrame(np.array(result),columns=['ImageId','Label'])\n",
    "output.to_csv('result.csv')\n",
    "output.head()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b88b4056ba75e2f2b5a10f86f3e99d2d302c45f6cf4f1612b79ca25e2827868a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
